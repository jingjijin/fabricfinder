{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape image urls from fabrics.com website\n",
    "\n",
    "def scrape_image_urls(url, pages):\n",
    "\n",
    "    imgs = []\n",
    "    urls = []\n",
    "    \n",
    "    for page in range(pages):\n",
    "        html = urlopen(url + str(page + 1))\n",
    "        soup = BeautifulSoup(html)\n",
    "        imgs += soup.findAll('div',{'class': 'product-item-image'})\n",
    "        time.sleep(2)\n",
    "        \n",
    "    for img in imgs:\n",
    "        try: urls.append(img.find('img')['src'])\n",
    "        except: pass\n",
    "        \n",
    "    return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this for scrape specific fabric type\n",
    "\n",
    "url = '' # add url except for the page\n",
    "pages =  # add page counts\n",
    "fabric = '' # add fabric type str here\n",
    "\n",
    "url_name = fabric + '_url'\n",
    "url_name = scrape_image_urls(url, pages)\n",
    "print(len(url_name))\n",
    "\n",
    "pd.DataFrame(fauxfur_url).to_csv(fabric + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250\n"
     ]
    }
   ],
   "source": [
    "# scrape faux fur fabrics and save as csv file\n",
    "url = \"https://www.fabric.com/find?fabric-type=faux-fur&page=\"\n",
    "pages = 4\n",
    "\n",
    "fauxfur_url = scrape_image_urls(url, pages)\n",
    "print(len(fauxfur_url))\n",
    "\n",
    "pd.DataFrame(fauxfur_url).to_csv('fauxfur.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1050\n"
     ]
    }
   ],
   "source": [
    "# scrape velvet fabrics and save as csv file\n",
    "url = \"https://www.fabric.com/find?fabric-type=velvet&page=\"\n",
    "pages = 14\n",
    "\n",
    "velvet_url = scrape_image_urls(url, pages)\n",
    "print(len(velvet_url))\n",
    "\n",
    "pd.DataFrame(velvet_url).to_csv('velvet.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1050\n"
     ]
    }
   ],
   "source": [
    "# scrape velvet fabrics and save as csv file\n",
    "url = \"https://www.fabric.com/find?fiber-content-range=linen-or-linen-blends&usage=blankets-and-throws,home-decor-notions,pillows&page=\"\n",
    "pages = 14\n",
    "\n",
    "linen_url = scrape_image_urls(url, pages)\n",
    "print(len(linen_url))\n",
    "\n",
    "pd.DataFrame(linen_url).to_csv('linen.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
